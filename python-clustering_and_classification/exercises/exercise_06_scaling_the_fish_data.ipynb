{
    "nbformat": 4,
    "metadata": {
        "kernelspec": {
            "display_name": "Python [default]",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "pygments_lexer": "ipython3",
            "mimetype": "text/x-python",
            "nbconvert_exporter": "python",
            "file_extension": ".py",
            "version": "3.5.2",
            "name": "python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            }
        }
    },
    "nbformat_minor": 2,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exercise 6: Scaling fish data for clustering\n",
                "\n",
                "You are given an array `samples` giving measurements of fish.  Each row represents asingle fish.  The measurements, such as weight in grams, length in centimeters, and the percentage ratio of height to length, have very different scales.  In order to cluster this data effectively, you'll need to standardize these features first.  In this exercise, you'll build a pipeline to standardize and cluster the data.\n",
                "\n",
                "This great dataset was derived from the one [here](http://svitsrv25.epfl.ch/R-doc/library/rrcov/html/fish.html), where you can see a description of each measurement."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From the course _Transition to Data Science_. [Buy the entire course for just $10](https://www.udemy.com/transition-to-data-science-in-python/?couponCode=CLUSTER-NBS) for many more exercises and helpful video lectures."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 1:** Load the dataset _(this bit is written for you)_."
            ]
        },
        {
            "execution_count": null,
            "cell_type": "code",
            "metadata": {
                "collapsed": true,
                "exercise": false
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "df = pd.read_csv('../datasets/fish.csv')\n",
                "\n",
                "# forget the species column for now - we'll use it later!\n",
                "del df['species']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 2:** Call `df.head()` to inspect the dataset:"
            ]
        },
        {
            "execution_count": null,
            "cell_type": "code",
            "metadata": {
                "collapsed": false
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 3:** Extract all the measurements as a 2D NumPy array, assigning to `samples` (hint: use the `.values` attribute of `df`)"
            ]
        },
        {
            "execution_count": null,
            "cell_type": "code",
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 4:** Perform the necessary imports:\n",
                "\n",
                "- `make_pipeline` from `sklearn.pipeline`.\n",
                "- `StandardScaler` from `sklearn.preprocessing`.\n",
                "- `KMeans` from `sklearn.cluster`.\n"
            ]
        },
        {
            "execution_count": null,
            "cell_type": "code",
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 5:** Create an instance of `StandardScaler` called `scaler`."
            ]
        },
        {
            "execution_count": null,
            "cell_type": "code",
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 6:** Create an instance of `KMeans` with `4` clusters called `kmeans`."
            ]
        },
        {
            "execution_count": null,
            "cell_type": "code",
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 7:** Create a pipeline called `pipeline` that chains `scaler` and `kmeans`. To do this, you just need to pass them in as arguments to `make_pipeline()`."
            ]
        },
        {
            "execution_count": null,
            "cell_type": "code",
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Great job!** Now you're all set to transform the fish measurements and perform the clustering.  Let's get to it in the next exercise!"
            ]
        },
        {
            "execution_count": null,
            "cell_type": "code",
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        }
    ]
}